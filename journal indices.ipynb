{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook reads an excel file with ISSNand retrives journal information from Scimago. ISSns should not contains \"-\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "df = pd.read_excel('deduplicated.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[['ISSN']].drop_duplicates().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu = df['ISSN'].value_counts().reset_index()\n",
    "dfu.columns = ['ISSN', '# papers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_page(iss):\n",
    "    while True:\n",
    "        try:\n",
    "            search_base = 'https://www.scimagojr.com/journalsearch.php?q='\n",
    "            url = search_base+iss\n",
    "            res = requests.get(url).text\n",
    "            soup = BeautifulSoup(res)\n",
    "            s = 'Sorry, no results were found.'\n",
    "            if s in soup.text:\n",
    "                output.append(row)\n",
    "                print('No result!')\n",
    "                print(iss, 't2')\n",
    "                return None\n",
    "            res = soup.findAll('div',{'class':\"search_results\"})\n",
    "            journal_relative_url = [x['href'] for x in res[0].findAll('a')][0]\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(60)\n",
    "    return journal_relative_url\n",
    "\n",
    "def get_page(journal_relative_url):\n",
    "    journal_full_url = 'https://www.scimagojr.com/'+journal_relative_url\n",
    "    journal_page = requests.get(journal_full_url).text\n",
    "    soup = BeautifulSoup(journal_page)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20080387\n",
      "journalsearch.php?q=19700187808&tip=sid&clean=0\n",
      "1\n",
      "09697330\n",
      "journalsearch.php?q=28836&tip=sid&clean=0\n",
      "2\n",
      "00309982\n",
      "journalsearch.php?q=16479&tip=sid&clean=0\n",
      "3\n",
      "14726939\n",
      "journalsearch.php?q=28100&tip=sid&clean=0\n",
      "4\n",
      "10203397\n",
      "journalsearch.php?q=20214&tip=sid&clean=0\n",
      "5\n",
      "00411345\n",
      "journalsearch.php?q=19279&tip=sid&clean=0\n",
      "6\n",
      "22516085\n",
      "journalsearch.php?q=21484&tip=sid&clean=0\n",
      "7\n",
      "1682024X\n",
      "journalsearch.php?q=16469&tip=sid&clean=0\n",
      "8\n",
      "1022386X\n",
      "journalsearch.php?q=29808&tip=sid&clean=0\n",
      "9\n",
      "03795284\n",
      "journalsearch.php?q=18826&tip=sid&clean=0\n",
      "10\n",
      "22779531\n",
      "journalsearch.php?q=21100904390&tip=sid&clean=0\n",
      "11\n",
      "19967195\n",
      "journalsearch.php?q=21100215707&tip=sid&clean=0\n",
      "12\n",
      "10292977\n",
      "journalsearch.php?q=27539&tip=sid&clean=0\n",
      "13\n",
      "14726920\n",
      "journalsearch.php?q=28099&tip=sid&clean=0\n",
      "14\n",
      "14726955\n",
      "journalsearch.php?q=27155&tip=sid&clean=0\n",
      "15\n",
      "13192442\n",
      "journalsearch.php?q=5000154608&tip=sid&clean=0\n",
      "16\n",
      "03066800\n",
      "journalsearch.php?q=15962&tip=sid&clean=0\n",
      "17\n",
      "0142159X\n",
      "journalsearch.php?q=18357&tip=sid&clean=0\n",
      "18\n",
      "19326203\n",
      "journalsearch.php?q=10600153309&tip=sid&clean=0\n",
      "19\n",
      "00224197\n",
      "journalsearch.php?q=27339&tip=sid&clean=0\n",
      "20\n",
      "17359066\n",
      "journalsearch.php?q=21100898964&tip=sid&clean=0\n",
      "21\n",
      "14718731\n",
      "journalsearch.php?q=22886&tip=sid&clean=0\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "subjects = []\n",
    "from tqdm.notebook import tqdm\n",
    "for i, row in enumerate(dfu.values):\n",
    "    print(i)\n",
    "    iss, journal = row\n",
    "    print(iss)\n",
    "    row = ['']*6\n",
    "    row[3] = journal\n",
    "    row[-1] = iss\n",
    "    if type(iss) == float:\n",
    "        output.append(row)\n",
    "        print(iss, 't1')\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        journal_relative_url = finding_page(iss)\n",
    "        break\n",
    "    print(journal_relative_url)\n",
    "    if not journal_relative_url:\n",
    "        continue\n",
    "    journal_full_url = 'https://www.scimagojr.com/'+journal_relative_url\n",
    "    \n",
    "    while True:\n",
    "         try:\n",
    "            soup = get_page(journal_relative_url)\n",
    "            if '500 Internal Server Error' in soup.text:\n",
    "                time.sleep(60)\n",
    "                continue\n",
    "            break\n",
    "         except:\n",
    "             time.sleep(60)\n",
    "    \n",
    "    issns = soup.findAll('div', {'class': 'journalgrid'})[0].findAll('div')[5].findAll('p')[0].text.split(', ')\n",
    "    issns = [x.strip('X').strip('x') for x in issns]\n",
    "    if not iss.strip('x').strip('X') in issns:\n",
    "        row = ['']*6\n",
    "        row[3] = journal\n",
    "        row[-1] = iss\n",
    "        output.append(row)\n",
    "        print(iss, 't4')\n",
    "        continue\n",
    "    #print(journal, issn)\n",
    "    s = \"Sorry, no results were found.\"\n",
    "    tabels = soup.findAll('div', {'class': 'cellslide'})\n",
    "    q = []\n",
    "    q.append(journal)\n",
    "    sjr = [x.text for x in tabels[3].findAll('tr')[-1].findAll('td')][1]\n",
    "    q.append(sjr)\n",
    "    country = soup.findAll('div', {'class': 'journalgrid'})[0].findAll('a')[0].text\n",
    "    q.append(country)\n",
    "    h = soup.find('p', {'class': 'hindexnumber'}).text\n",
    "    q.append(h)\n",
    "    q.append(iss)\n",
    "    if len(soup.findAll(attrs={'alt': 'open access'}))>0:\n",
    "        q.append(1)\n",
    "    else:\n",
    "        q.append(0)\n",
    "    output.append(q)\n",
    "    try:\n",
    "        qs = [[y.text for y in x.findAll('td')]+[iss] for x in tabels[1].findAll('tr')[1:] if x.findAll('td')[1].text=='2022']\n",
    "    except:\n",
    "        qs = [[x.text, '2022', '', iss] for x in soup.findAll('div', {'class': 'journalgrid'})[0].findAll('div')[1].findAll('a')  if '00' not in x['href']]\n",
    "    subjects.extend(qs)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([x for x in output], columns = ['Count', 'SJR', 'Country', 'Hindex', 'ISSN', 'Open Access'])#.to_excel('journals measures.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(subjects, columns = ['Subject', 'Year', 'Q', 'ISSN'])\n",
    "del temp['Year']\n",
    "temp#.to_excel('journals subjects.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
